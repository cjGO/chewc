"""Common operations around the core datastructures for running a sim"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/08_select.ipynb.

# %% auto 0
__all__ = ['SelectionMethod', 'TruncationSelection', 'ImprovedThompsonSampling']

# %% ../nbs/08_select.ipynb 3
from flax.struct import dataclass as flax_dataclass
import jax.numpy as jnp
from typing import Optional
from .population import Population


import jax
import jax.numpy as jnp
from fastcore.test import test_eq, test_close, test_fail
import time

# Import required chewc components
from .population import Population, quick_haplo
from .sp import SimParam
from .trait import add_trait_a
from .phenotype import set_pheno
from .predict import gblup_predict

# %% ../nbs/08_select.ipynb 4
class SelectionMethod:
    """Base class for selection methods"""
    def __init__(self, name: str):
        self.name = name
    
    def select_parents(self, key, pop, sp, n_select, **kwargs):
        raise NotImplementedError

class TruncationSelection(SelectionMethod):
    """Truncation selection - select top individuals"""
    def __init__(self):
        super().__init__("Truncation")
    
    def select_parents(self, key, pop, sp, n_select, **kwargs):
        # Use breeding values if available, otherwise phenotypes
        if pop.bv is not None and jnp.var(pop.bv[:, 0]) > 1e-8:
            values = pop.bv[:, 0]
        else:
            values = pop.pheno[:, 0]
        
        # Get top n_select individuals
        top_indices = jnp.argsort(values)[-n_select:]
        return top_indices

class ImprovedThompsonSampling(SelectionMethod):
    """Improved Thompson sampling with better uncertainty handling"""
    def __init__(self):
        super().__init__("Thompson")
    
    def select_parents(self, key, pop, sp, n_select, **kwargs):
        h2 = kwargs.get('h2', 0.5)
        
        # Check if we have sufficient variation for genomic prediction
        phenotypic_variance = jnp.var(pop.pheno[:, 0])
        
        if phenotypic_variance < 1e-8:
            # No variation left - random selection
            return jax.random.choice(key, pop.nInd, shape=(n_select,), replace=False)
        
        try:
            # Get EBVs using GBLUP
            prediction_results = gblup_predict(pop, h2=h2, trait_idx=0)
            ebv_mean = prediction_results.ebv[:, 0]
            reliability = prediction_results.reliability
            
            # Improved posterior sampling
            # Higher uncertainty (lower reliability) -> more exploration
            # Lower uncertainty (higher reliability) -> more exploitation
            
            # Calculate prediction error variance for each individual
            genetic_var = jnp.var(ebv_mean)
            pred_error_var = genetic_var * (1 - reliability + 1e-6)  # Avoid zero variance
            
            # Sample from individual posterior distributions
            key, sample_key = jax.random.split(key)
            sample_keys = jax.random.split(sample_key, pop.nInd)
            
            # Each individual gets their own posterior sample
            sampled_values = jnp.array([
                jax.random.normal(sample_keys[i]) * jnp.sqrt(pred_error_var[i]) + ebv_mean[i]
                for i in range(pop.nInd)
            ])
            
            # Select based on top sampled values (not probabilistic sampling)
            # This maintains the "selection intensity" more directly
            selected_indices = jnp.argsort(sampled_values)[-n_select:]
            
            return selected_indices
            
        except Exception as e:
            print(f"    GBLUP failed: {str(e)[:50]}..., using breeding values")
            # Fallback to breeding value-based selection with noise
            if pop.bv is not None:
                values = pop.bv[:, 0]
                # Add some exploration noise
                key, noise_key = jax.random.split(key)
                noise = jax.random.normal(noise_key, values.shape) * jnp.std(values) * 0.1
                noisy_values = values + noise
                selected_indices = jnp.argsort(noisy_values)[-n_select:]
                return selected_indices
            else:
                return jax.random.choice(key, pop.nInd, shape=(n_select,), replace=False)

