{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict\n",
    "\n",
    "> Common operations around the core datastructures for running a sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from flax.struct import dataclass as flax_dataclass\n",
    "import jax.numpy as jnp\n",
    "from typing import Optional\n",
    "from chewc.population import Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\"\"\"\n",
    "GBLUP (Genomic Best Linear Unbiased Prediction) implementation for chewc library.\n",
    "\n",
    "This module provides functions for genomic prediction using the GBLUP methodology,\n",
    "which is a standard approach in genomic selection and animal breeding.\n",
    "\"\"\"\n",
    "\n",
    "from typing import Optional, Dict\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.numpy.linalg import solve, inv, pinv\n",
    "from flax.struct import dataclass as flax_dataclass\n",
    "\n",
    "from chewc.population import Population\n",
    "\n",
    "@flax_dataclass(frozen=True)\n",
    "class PredictionResults:\n",
    "    \"\"\"\n",
    "    A container for the results of a genomic prediction.\n",
    "    \"\"\"\n",
    "    ids: jnp.ndarray\n",
    "    ebv: jnp.ndarray\n",
    "    pev: Optional[jnp.ndarray] = None\n",
    "    reliability: Optional[jnp.ndarray] = None\n",
    "    fixed_effects: Optional[jnp.ndarray] = None\n",
    "    h2_used: Optional[float] = None\n",
    "    var_components: Optional[Dict] = None\n",
    "\n",
    "\n",
    "def _gblup_core(\n",
    "    phenotypes: jnp.ndarray,\n",
    "    dosages: jnp.ndarray,\n",
    "    h2: float,\n",
    "    trait_idx: int = 0,\n",
    "    regularization: float = 1e-6\n",
    ") -> tuple[jnp.ndarray, jnp.ndarray, jnp.ndarray, dict]:\n",
    "    \"\"\"\n",
    "    Core GBLUP calculation. Handles both full and missing data cases.\n",
    "    \"\"\"\n",
    "    y = phenotypes[:, trait_idx]\n",
    "    n_total = dosages.shape[0]\n",
    "\n",
    "    valid_mask = ~jnp.isnan(y)\n",
    "    n_valid = jnp.sum(valid_mask).item()\n",
    "\n",
    "    if n_valid == 0:\n",
    "        raise ValueError(\"No valid (non-NaN) phenotypes found for the selected trait.\")\n",
    "\n",
    "    # --- Shared calculations ---\n",
    "    p = jnp.mean(dosages[valid_mask], axis=0) / 2 # Allele freqs from phenotyped pop\n",
    "    W_all = dosages - 2 * p\n",
    "    denom = 2 * jnp.sum(p * (1 - p))\n",
    "    G_all = (W_all @ W_all.T) / (denom + regularization)\n",
    "\n",
    "    y_valid = y[valid_mask]\n",
    "    y_mean = jnp.mean(y_valid)\n",
    "    y_centered = y_valid - y_mean\n",
    "    \n",
    "    var_y = jnp.var(y_valid)\n",
    "    var_g = h2 * var_y\n",
    "    var_e = (1 - h2) * var_y\n",
    "\n",
    "    # --- Case 1: All individuals have phenotypes (no partitioning needed) ---\n",
    "    if n_valid == n_total:\n",
    "        G_reg = G_all + jnp.eye(n_total) * regularization\n",
    "        lambda_val = var_e / (var_g + regularization)\n",
    "        X = jnp.ones((n_total, 1))\n",
    "        Z = jnp.eye(n_total)\n",
    "        G_inv = pinv(G_reg)\n",
    "\n",
    "        C11 = X.T @ X\n",
    "        C12 = X.T @ Z\n",
    "        C22 = Z.T @ Z + G_inv * lambda_val\n",
    "        LHS = jnp.block([[C11, C12], [C12.T, C22]])\n",
    "        RHS = jnp.concatenate([X.T @ y_centered, Z.T @ y_centered])\n",
    "        \n",
    "        try:\n",
    "            solutions = solve(LHS, RHS)\n",
    "            C_inv = inv(LHS)\n",
    "        except jnp.linalg.LinAlgError:\n",
    "            solutions = pinv(LHS) @ RHS\n",
    "            C_inv = pinv(LHS)\n",
    "\n",
    "        b_hat = solutions[:1]\n",
    "        ebv_full = solutions[1:]\n",
    "        \n",
    "        pev_full = jnp.diag(C_inv[1:, 1:]) * var_e\n",
    "        reliability_full = jnp.clip(1 - (pev_full / (var_g + regularization)), 0.0, 1.0)\n",
    "        \n",
    "    # --- Case 2: Some individuals have missing phenotypes (partitioning required) ---\n",
    "    else:\n",
    "        G_11 = G_all[valid_mask][:, valid_mask]\n",
    "        G_21 = G_all[~valid_mask][:, valid_mask]\n",
    "        G_22 = G_all[~valid_mask][:, ~valid_mask]\n",
    "    \n",
    "        G_11_reg = G_11 + jnp.eye(n_valid) * regularization\n",
    "        lambda_val = var_e / (var_g + regularization)\n",
    "        X1 = jnp.ones((n_valid, 1))\n",
    "        Z1 = jnp.eye(n_valid)\n",
    "        G_11_inv = pinv(G_11_reg)\n",
    "\n",
    "        C11 = X1.T @ X1\n",
    "        C12 = X1.T @ Z1\n",
    "        C22 = Z1.T @ Z1 + G_11_inv * lambda_val\n",
    "        LHS = jnp.block([[C11, C12], [C12.T, C22]])\n",
    "        RHS = jnp.concatenate([X1.T @ y_centered, Z1.T @ y_centered])\n",
    "\n",
    "        try:\n",
    "            solutions = solve(LHS, RHS)\n",
    "            C_inv = inv(LHS)\n",
    "        except jnp.linalg.LinAlgError:\n",
    "            solutions = pinv(LHS) @ RHS\n",
    "            C_inv = pinv(LHS)\n",
    "\n",
    "        b_hat = solutions[:1]\n",
    "        u_hat_1 = solutions[1:]\n",
    "        u_hat_2 = G_21 @ G_11_inv @ u_hat_1\n",
    "        \n",
    "        ebv_full = jnp.zeros(n_total).at[valid_mask].set(u_hat_1).at[~valid_mask].set(u_hat_2)\n",
    "        \n",
    "        pev_1 = jnp.diag(C_inv[1:, 1:]) * var_e\n",
    "        rel_1 = jnp.clip(1 - (pev_1 / (var_g + regularization)), 0.0, 1.0)\n",
    "        \n",
    "        pev_2 = jnp.diag(G_22 - G_21 @ G_11_inv @ G_21.T) * var_g\n",
    "        rel_2 = jnp.clip(1 - (pev_2 / (var_g + regularization)), 0.0, 1.0)\n",
    "        \n",
    "        pev_full = jnp.zeros(n_total).at[valid_mask].set(pev_1).at[~valid_mask].set(pev_2)\n",
    "        reliability_full = jnp.zeros(n_total).at[valid_mask].set(rel_1).at[~valid_mask].set(rel_2)\n",
    "\n",
    "    # --- Shared summary statistics ---\n",
    "    h2_realized = jnp.var(ebv_full[valid_mask]) / (var_y + 1e-8)\n",
    "    var_components = {\n",
    "        'var_genetic': var_g, 'var_error': var_e, 'var_phenotypic': var_y,\n",
    "        'h2_input': h2, 'h2_realized': h2_realized,\n",
    "        'intercept': y_mean + b_hat[0], 'n_valid': n_valid\n",
    "    }\n",
    "    return ebv_full, pev_full, reliability_full, var_components\n",
    "\n",
    "\n",
    "def gblup_predict(\n",
    "    pop: Population,\n",
    "    h2: float,\n",
    "    trait_idx: int = 0,\n",
    "    regularization: float = 1e-6\n",
    ") -> PredictionResults:\n",
    "    \"\"\"\n",
    "    Predicts breeding values using GBLUP (Genomic Best Linear Unbiased Prediction).\n",
    "    \"\"\"\n",
    "    if not (0 <= h2 <= 1):\n",
    "        raise ValueError(f\"Heritability must be between 0 and 1, got {h2}\")\n",
    "    if pop.pheno.shape[1] <= trait_idx:\n",
    "        raise IndexError(f\"trait_idx {trait_idx} is out of bounds for {pop.pheno.shape[1]} traits\")\n",
    "    if pop.nInd == 0:\n",
    "        raise ValueError(\"Population is empty\")\n",
    "\n",
    "    ebv, pev, reliability, var_components = _gblup_core(\n",
    "        pop.pheno, pop.dosage, h2, trait_idx=trait_idx, regularization=regularization\n",
    "    )\n",
    "\n",
    "    return PredictionResults(\n",
    "        ids=pop.id,\n",
    "        ebv=ebv.reshape(-1, 1),\n",
    "        pev=pev,\n",
    "        reliability=reliability,\n",
    "        fixed_effects=jnp.array([var_components['intercept']]),\n",
    "        h2_used=h2,\n",
    "        var_components=var_components\n",
    "    )\n",
    "\n",
    "\n",
    "def gblup_multi_trait(\n",
    "    pop: Population,\n",
    "    h2: jnp.ndarray,\n",
    "    regularization: float = 1e-6\n",
    ") -> list[PredictionResults]:\n",
    "    \"\"\"\n",
    "    Performs GBLUP prediction for multiple traits independently.\n",
    "    \"\"\"\n",
    "    if h2.ndim == 0:\n",
    "        h2 = jnp.array([h2])\n",
    "    if len(h2) != pop.pheno.shape[1]:\n",
    "        raise ValueError(f\"Number of h2 values ({len(h2)}) must match number of traits ({pop.pheno.shape[1]})\")\n",
    "\n",
    "    results = []\n",
    "    for trait_idx, h2_val in enumerate(h2):\n",
    "        result = gblup_predict(pop, float(h2_val), trait_idx, regularization)\n",
    "        results.append(result)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| test\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# --- Import your revised GBLUP code ---\n",
    "# To make this runnable, you would save the code above as, for example, `gblup.py`\n",
    "# and then import it like this:\n",
    "# from gblup import gblup_predict\n",
    "from __main__ import gblup_predict # Or use this line if running in the same file/notebook\n",
    "\n",
    "# --- Import chewc library components ---\n",
    "# This assumes 'chewc' is installed and accessible in your environment\n",
    "from chewc.population import Population, quick_haplo\n",
    "from chewc.sp import SimParam\n",
    "from chewc.trait import add_trait_a\n",
    "from chewc.phenotype import set_pheno\n",
    "\n",
    "\n",
    "def test_gblup_accuracy():\n",
    "    \"\"\"\n",
    "    Tests the GBLUP implementation by comparing its predictions\n",
    "    to known, simulated breeding values.\n",
    "    \"\"\"\n",
    "    print(\"ðŸš€ Starting GBLUP accuracy test...\")\n",
    "\n",
    "    # 1. Simulation parameters\n",
    "    n_ind = 250\n",
    "    n_loci_per_chr = 1000\n",
    "    n_chr = 1\n",
    "    h2_simulated = 0.5  # The true heritability used to generate data\n",
    "    h2_for_gblup = 0.5  # The heritability we provide to the GBLUP model\n",
    "\n",
    "    # 2. Setup JAX random keys\n",
    "    key = jax.random.PRNGKey(42)\n",
    "    founder_key, trait_key, pheno_key = jax.random.split(key, 3)\n",
    "\n",
    "    # 3. Create a founder population using chewc\n",
    "    print(f\"ðŸ§¬ Simulating a population with {n_ind} individuals and {n_loci_per_chr} loci...\")\n",
    "    founder_pop, gen_map = quick_haplo(\n",
    "        key=founder_key,\n",
    "        n_ind=n_ind,\n",
    "        n_chr=n_chr,\n",
    "        n_loci_per_chr=n_loci_per_chr\n",
    "    )\n",
    "\n",
    "    # 4. Define simulation parameters and add a quantitative trait\n",
    "    sp = SimParam.from_founder_pop(founder_pop, gen_map)\n",
    "    sp = add_trait_a(\n",
    "        key=trait_key,\n",
    "        founder_pop=founder_pop,\n",
    "        sim_param=sp,\n",
    "        n_qtl_per_chr=150,      # A reasonably polygenic trait\n",
    "        mean=jnp.array([10.0]), # With a non-zero mean\n",
    "        var=jnp.array([2.0])    # And some genetic variance\n",
    "    )\n",
    "\n",
    "    # 5. Generate phenotypes based on the true genetics and simulated heritability\n",
    "    print(f\"ðŸŒ± Generating phenotypes with a true hÂ² of {h2_simulated}...\")\n",
    "    pop_with_pheno = set_pheno(\n",
    "        key=pheno_key,\n",
    "        pop=founder_pop,\n",
    "        traits=sp.traits,\n",
    "        ploidy=sp.ploidy,\n",
    "        h2=jnp.array([h2_simulated])\n",
    "    )\n",
    "\n",
    "    # 6. Run the GBLUP prediction using the specified h2\n",
    "    print(f\"ðŸ“ˆ Running GBLUP prediction with an input hÂ² of {h2_for_gblup}...\")\n",
    "    results = gblup_predict(pop=pop_with_pheno, h2=h2_for_gblup)\n",
    "\n",
    "    # 7. Validate the results\n",
    "    true_bvs = pop_with_pheno.bv.flatten()\n",
    "    estimated_bvs = results.ebv.flatten()\n",
    "\n",
    "    # Calculate the correlation between true and estimated BVs.\n",
    "    # This is a key metric for \"prediction accuracy\".\n",
    "    prediction_accuracy = jnp.corrcoef(true_bvs, estimated_bvs)[0, 1]\n",
    "    \n",
    "    # Calculate the regression of true BVs on estimated BVs.\n",
    "    # A value close to 1 indicates that the EBVs are not biased (scaled correctly).\n",
    "    regression_b_on_a = jnp.cov(true_bvs, estimated_bvs)[0, 1] / jnp.var(estimated_bvs)\n",
    "\n",
    "    print(\"\\n--- âœ… Test Validation ---\")\n",
    "    print(f\"Prediction Accuracy (Correlation): {prediction_accuracy:.4f}\")\n",
    "    print(f\"Regression of True BV on EBV:     {regression_b_on_a:.4f}\")\n",
    "\n",
    "    # --- Assertions for automated testing ---\n",
    "    # The expected accuracy is roughly sqrt(h2). We'll test for a reasonable value.\n",
    "    assert prediction_accuracy > 0.6, f\"Prediction accuracy ({prediction_accuracy:.2f}) is lower than expected.\"\n",
    "    \n",
    "    # The regression coefficient should be close to 1, indicating unbiased predictions.\n",
    "    assert 0.9 < regression_b_on_a < 1.1, f\"EBV estimates appear biased (regression={regression_b_on_a:.2f}).\"\n",
    "    \n",
    "    # Check that the output shapes are correct\n",
    "    assert results.ebv.shape == (n_ind, 1)\n",
    "    assert results.reliability.shape == (n_ind,)\n",
    "    \n",
    "    # Check that reliability is within the valid range [0, 1]\n",
    "    assert jnp.all(results.reliability >= 0) and jnp.all(results.reliability <= 1)\n",
    "    print(\"\\nðŸŽ‰ All assertions passed!\")\n",
    "\n",
    "\n",
    "def test_gblup_with_missing_phenotypes():\n",
    "    \"\"\"\n",
    "    Tests that GBLUP can handle missing phenotypes (NaNs) and still provide\n",
    "    predictions for all individuals.\n",
    "    \"\"\"\n",
    "    print(\"\\nðŸš€ Starting GBLUP test with missing phenotypes...\")\n",
    "\n",
    "    # 1. Simulation parameters (same as before)\n",
    "    n_ind = 300\n",
    "    n_loci_per_chr = 1000\n",
    "    n_chr = 1\n",
    "    h2 = 0.6  # Using a slightly higher h2 to make the effect clearer\n",
    "    missing_fraction = 0.4 # 40% of individuals will have no phenotype\n",
    "\n",
    "    # 2. Setup JAX random keys\n",
    "    key = jax.random.PRNGKey(101)\n",
    "    founder_key, trait_key, pheno_key, missing_key = jax.random.split(key, 4)\n",
    "\n",
    "    # 3. Create a base population\n",
    "    print(f\"ðŸ§¬ Simulating a population with {n_ind} individuals...\")\n",
    "    founder_pop, gen_map = quick_haplo(\n",
    "        key=founder_key, n_ind=n_ind, n_chr=n_chr, n_loci_per_chr=n_loci_per_chr\n",
    "    )\n",
    "    sp = SimParam.from_founder_pop(founder_pop, gen_map)\n",
    "    sp = add_trait_a(\n",
    "        key=trait_key,\n",
    "        founder_pop=founder_pop,\n",
    "        sim_param=sp,\n",
    "        n_qtl_per_chr=150,\n",
    "        mean=jnp.array([10.0]),\n",
    "        var=jnp.array([2.0]),\n",
    "    )\n",
    "    pop_with_pheno = set_pheno(\n",
    "        key=pheno_key,\n",
    "        pop=founder_pop,\n",
    "        traits=sp.traits,\n",
    "        ploidy=sp.ploidy,\n",
    "        h2=jnp.array([h2]),\n",
    "    )\n",
    "\n",
    "    # 4. Introduce missing phenotypes\n",
    "    n_missing = int(n_ind * missing_fraction)\n",
    "    print(f\"ðŸ”ª Introducing {n_missing} missing phenotypes (NaNs)...\")\n",
    "    \n",
    "    # Create a boolean mask for which individuals will have phenotypes\n",
    "    phenotyped_indices = jax.random.choice(missing_key, n_ind, shape=(n_ind - n_missing,), replace=False)\n",
    "    phenotyped_mask = jnp.zeros(n_ind, dtype=bool).at[phenotyped_indices].set(True)\n",
    "    \n",
    "    # Create the new phenotype array with NaNs\n",
    "    pheno_with_missing = jnp.where(\n",
    "        phenotyped_mask[:, None],  # Ensure mask is broadcastable to pheno shape\n",
    "        pop_with_pheno.pheno,\n",
    "        jnp.nan\n",
    "    )\n",
    "    pop_missing = pop_with_pheno.replace(pheno=pheno_with_missing)\n",
    "\n",
    "    # 5. Run GBLUP prediction\n",
    "    print(\"ðŸ“ˆ Running GBLUP prediction on incomplete data...\")\n",
    "    results = gblup_predict(pop=pop_missing, h2=h2)\n",
    "\n",
    "    # 6. Validate the results\n",
    "    true_bvs = pop_missing.bv.flatten()\n",
    "    estimated_bvs = results.ebv.flatten()\n",
    "\n",
    "    # --- Separate individuals into phenotyped and non-phenotyped groups ---\n",
    "    bvs_phenotyped = true_bvs[phenotyped_mask]\n",
    "    ebvs_phenotyped = estimated_bvs[phenotyped_mask]\n",
    "    \n",
    "    bvs_non_phenotyped = true_bvs[~phenotyped_mask]\n",
    "    ebvs_non_phenotyped = estimated_bvs[~phenotyped_mask]\n",
    "\n",
    "    # --- Calculate accuracies for each group ---\n",
    "    accuracy_phenotyped = jnp.corrcoef(bvs_phenotyped, ebvs_phenotyped)[0, 1]\n",
    "    accuracy_non_phenotyped = jnp.corrcoef(bvs_non_phenotyped, ebvs_non_phenotyped)[0, 1]\n",
    "    \n",
    "    print(\"\\n--- âœ… Test Validation ---\")\n",
    "    print(f\"Accuracy for individuals WITH phenotypes:   {accuracy_phenotyped:.4f}\")\n",
    "    print(f\"Accuracy for individuals WITHOUT phenotypes: {accuracy_non_phenotyped:.4f}\")\n",
    "\n",
    "    # --- Assertions for automated testing ---\n",
    "    # The function should not produce any NaNs in the output EBVs\n",
    "    assert not jnp.any(jnp.isnan(results.ebv)), \"Output EBVs should not contain NaNs.\"\n",
    "    \n",
    "    # Accuracy for phenotyped group should be high\n",
    "    assert accuracy_phenotyped > jnp.sqrt(h2) * 0.8, \"Accuracy for phenotyped individuals is too low.\"\n",
    "\n",
    "    # Accuracy for non-phenotyped group should be lower, but still positive\n",
    "    assert accuracy_non_phenotyped > 0.1, \"Accuracy for non-phenotyped individuals should be positive.\"\n",
    "    assert accuracy_non_phenotyped < accuracy_phenotyped, \"Non-phenotyped accuracy should not be higher than phenotyped.\"\n",
    "\n",
    "    # Average reliability should be lower for the non-phenotyped group\n",
    "    reliability_phenotyped = jnp.mean(results.reliability[phenotyped_mask])\n",
    "    reliability_non_phenotyped = jnp.mean(results.reliability[~phenotyped_mask])\n",
    "    print(f\"Average reliability (phenotyped):           {reliability_phenotyped:.4f}\")\n",
    "    print(f\"Average reliability (non-phenotyped):       {reliability_non_phenotyped:.4f}\")\n",
    "    assert reliability_non_phenotyped < reliability_phenotyped, \"Reliability should be lower for non-phenotyped individuals.\"\n",
    "    \n",
    "    print(\"\\nðŸŽ‰ All assertions passed!\")\n",
    "\n",
    "\n",
    "\n",
    "def test_gblup_heritability_effect():\n",
    "    \"\"\"\n",
    "    Tests that prediction accuracy increases with higher heritability.\n",
    "    \"\"\"\n",
    "    print(\"\\nðŸš€ Starting GBLUP heritability effect test...\")\n",
    "\n",
    "    # --- Helper function to run a single simulation and prediction ---\n",
    "    def run_sim_and_predict(key, h2):\n",
    "        founder_key, trait_key, pheno_key = jax.random.split(key, 3)\n",
    "        pop, gen_map = quick_haplo(key=founder_key, n_ind=250, n_chr=1, n_loci_per_chr=1000)\n",
    "        sp = SimParam.from_founder_pop(pop, gen_map)\n",
    "        sp = add_trait_a(\n",
    "            key=trait_key, founder_pop=pop, sim_param=sp, n_qtl_per_chr=150,\n",
    "            mean=jnp.array([0.]), var=jnp.array([1.])\n",
    "        )\n",
    "        pop_with_pheno = set_pheno(\n",
    "            key=pheno_key, pop=pop, traits=sp.traits, ploidy=sp.ploidy,\n",
    "            h2=jnp.array([h2])\n",
    "        )\n",
    "        results = gblup_predict(pop=pop_with_pheno, h2=h2)\n",
    "        accuracy = jnp.corrcoef(pop_with_pheno.bv.flatten(), results.ebv.flatten())[0, 1]\n",
    "        return accuracy\n",
    "\n",
    "    # 1. Setup keys\n",
    "    key = jax.random.PRNGKey(202)\n",
    "    key_low_h2, key_high_h2 = jax.random.split(key)\n",
    "\n",
    "    # 2. Run for low and high heritability\n",
    "    h2_low = 0.2\n",
    "    h2_high = 0.8\n",
    "    print(f\"ðŸ“ˆ Running prediction for low hÂ² ({h2_low})...\")\n",
    "    accuracy_low = run_sim_and_predict(key_low_h2, h2_low)\n",
    "    \n",
    "    print(f\"ðŸ“ˆ Running prediction for high hÂ² ({h2_high})...\")\n",
    "    accuracy_high = run_sim_and_predict(key_high_h2, h2_high)\n",
    "\n",
    "    print(\"\\n--- âœ… Test Validation ---\")\n",
    "    print(f\"Prediction Accuracy (hÂ²={h2_low}): {accuracy_low:.4f}\")\n",
    "    print(f\"Prediction Accuracy (hÂ²={h2_high}): {accuracy_high:.4f}\")\n",
    "\n",
    "    # 3. Assert that higher heritability leads to higher accuracy\n",
    "    assert accuracy_high > accuracy_low, \"Accuracy should be higher for a more heritable trait.\"\n",
    "    # Also check that both are reasonably positive\n",
    "    assert accuracy_low > 0.2, \"Low h2 accuracy is lower than expected.\"\n",
    "    assert accuracy_high > 0.7, \"High h2 accuracy is lower than expected.\"\n",
    "\n",
    "    print(\"\\nðŸŽ‰ All assertions passed!\")\n",
    "\n",
    "def test_gblup_pop_size_effect_on_reliability():\n",
    "    \"\"\"\n",
    "    Tests that the average reliability of predictions increases with a larger\n",
    "    reference population size.\n",
    "    \"\"\"\n",
    "    print(\"\\nðŸš€ Starting GBLUP population size effect test...\")\n",
    "\n",
    "    # --- Helper function to run a single simulation and get avg reliability ---\n",
    "    def get_avg_reliability(key, n_ind, h2):\n",
    "        founder_key, trait_key, pheno_key = jax.random.split(key, 3)\n",
    "        pop, gen_map = quick_haplo(\n",
    "            key=founder_key, n_ind=n_ind, n_chr=1, n_loci_per_chr=1000\n",
    "        )\n",
    "        sp = SimParam.from_founder_pop(pop, gen_map)\n",
    "        sp = add_trait_a(\n",
    "            key=trait_key, founder_pop=pop, sim_param=sp, n_qtl_per_chr=150,\n",
    "            mean=jnp.array([0.]), var=jnp.array([1.])\n",
    "        )\n",
    "        pop_with_pheno = set_pheno(\n",
    "            key=pheno_key, pop=pop, traits=sp.traits, ploidy=sp.ploidy,\n",
    "            h2=jnp.array([h2])\n",
    "        )\n",
    "        results = gblup_predict(pop=pop_with_pheno, h2=h2)\n",
    "        return jnp.mean(results.reliability)\n",
    "\n",
    "    # 1. Setup keys and parameters\n",
    "    key = jax.random.PRNGKey(303)\n",
    "    key_small, key_large = jax.random.split(key)\n",
    "    h2 = 0.5\n",
    "    n_small = 100\n",
    "    n_large = 500\n",
    "\n",
    "    # 2. Run for small and large population sizes\n",
    "    print(f\"ðŸ“ˆ Running prediction for small population (n={n_small})...\")\n",
    "    reliability_small = get_avg_reliability(key_small, n_ind=n_small, h2=h2)\n",
    "\n",
    "    print(f\"ðŸ“ˆ Running prediction for large population (n={n_large})...\")\n",
    "    reliability_large = get_avg_reliability(key_large, n_ind=n_large, h2=h2)\n",
    "\n",
    "    print(\"\\n--- âœ… Test Validation ---\")\n",
    "    print(f\"Average Reliability (n={n_small}): {reliability_small:.4f}\")\n",
    "    print(f\"Average Reliability (n={n_large}): {reliability_large:.4f}\")\n",
    "\n",
    "    # 3. Assert that reliability is higher for the larger population\n",
    "    assert reliability_large > reliability_small, \"Reliability should increase with population size.\"\n",
    "    \n",
    "    print(\"\\nðŸŽ‰ All assertions passed!\")\n",
    "\n",
    "\n",
    "# --- To run all tests ---\n",
    "# if __name__ == \"__main__\":\n",
    "#     test_gblup_accuracy()\n",
    "#     test_gblup_with_missing_phenotypes()\n",
    "#     test_gblup_heritability_effect()\n",
    "#     test_gblup_pop_size_effect_on_reliability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
