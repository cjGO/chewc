{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4aeb5e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Resetting Environment ---\n",
      "Initial Observation (Gen 1): [  0.8      102.16094   13.672817]\n",
      "Initial Population Size: 200\n",
      "\n",
      "--- Running a Full Episode ---\n",
      "Gen 2: Mean Pheno=104.82, Reward=0.00, Done=False\n",
      "Gen 3: Mean Pheno=105.81, Reward=0.00, Done=False\n",
      "Gen 4: Mean Pheno=107.07, Reward=0.00, Done=False\n",
      "Gen 5: Mean Pheno=101.60, Reward=14.99, Done=True\n",
      "\n",
      "Final Cumulative Reward (equal to final TBV): 14.987\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from gymnax.environments import environment, spaces\n",
    "from typing import Tuple, Optional\n",
    "from functools import partial\n",
    "from jax.tree_util import tree_map\n",
    "\n",
    "# Assuming the 'chewc' library files are in the path\n",
    "from chewc.structs import Population, BreedingState, Trait, GeneticMap, quick_haplo, add_trait\n",
    "from chewc.pheno import calculate_phenotypes\n",
    "from chewc.cross import random_mating, cross_pair\n",
    "\n",
    "class StoaEnv(environment.Environment):\n",
    "    \"\"\"\n",
    "    A Gymnax environment for the ChewC breeding simulation.\n",
    "    \n",
    "    The agent's goal is to maximize the genetic gain of the population\n",
    "    over a fixed number of generations by choosing the selection intensity at each step.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_founders=100, n_pop_size=200, n_chr=5, n_loci=1000, n_qtl_per_chr=50, total_gen=20, max_crossovers=10):\n",
    "        super().__init__()\n",
    "        self.n_founders = n_founders\n",
    "        self.n_pop_size = n_pop_size\n",
    "        self.total_gen = total_gen\n",
    "        self.max_crossovers = max_crossovers\n",
    "        self.n_chr = n_chr\n",
    "        self.n_loci = n_loci\n",
    "        self.n_qtl_per_chr = n_qtl_per_chr\n",
    "        \n",
    "        key = jax.random.PRNGKey(42)\n",
    "        pop_key, trait_key = jax.random.split(key)\n",
    "\n",
    "        # Founder pop is created once and reused for every reset\n",
    "        self.founder_pop, self.genetic_map = quick_haplo(\n",
    "            key=pop_key, n_ind=self.n_founders, n_chr=self.n_chr, seg_sites=self.n_loci\n",
    "        )\n",
    "\n",
    "        self.trait_architecture = add_trait(\n",
    "            key=trait_key,\n",
    "            founder_pop=self.founder_pop,\n",
    "            n_qtl_per_chr=self.n_qtl_per_chr,\n",
    "            mean=jnp.array([100.0]),\n",
    "            var_a=jnp.array([10.0]),\n",
    "            var_d=jnp.array([0.0]),\n",
    "            sigma=jnp.array([[1.0]])\n",
    "        )\n",
    "        self.heritabilities = jnp.array([0.5])\n",
    "\n",
    "    @property\n",
    "    def default_params(self):\n",
    "        return {}\n",
    "\n",
    "    def step_env(self, key: jax.Array, state: BreedingState, action: jax.Array, params) -> Tuple[jax.Array, BreedingState, float, bool, dict]:\n",
    "        key, pheno_key, mating_key, cross_key = jax.random.split(key, 4)\n",
    "        current_pop = state.population\n",
    "        \n",
    "        selection_proportion = (action[0] + 1) / 2 * (0.95 - 0.05) + 0.05\n",
    "        \n",
    "        phenotypes, _ = calculate_phenotypes(\n",
    "            key=pheno_key,\n",
    "            population=current_pop,\n",
    "            trait=self.trait_architecture,\n",
    "            heritability=self.heritabilities\n",
    "        )\n",
    "        \n",
    "        n_current_pop = current_pop.geno.shape[0]\n",
    "        n_select = (n_current_pop * selection_proportion).astype(jnp.int32)\n",
    "        n_select = jnp.maximum(2, n_select)\n",
    "        \n",
    "        sorted_indices = jnp.argsort(-phenotypes[:, 0].flatten())\n",
    "        sorted_parent_pool = tree_map(lambda x: x[sorted_indices], current_pop)\n",
    "\n",
    "        pairings = random_mating(mating_key, n_parents=n_select, n_crosses=self.n_pop_size)\n",
    "        mother_indices, father_indices = pairings[:, 0], pairings[:, 1]\n",
    "        \n",
    "        mothers_geno = sorted_parent_pool.geno[mother_indices]\n",
    "        fathers_geno = sorted_parent_pool.geno[father_indices]\n",
    "        mothers_ibd = sorted_parent_pool.ibd[mother_indices]\n",
    "        fathers_ibd = sorted_parent_pool.ibd[father_indices]\n",
    "        \n",
    "        vmapped_cross = jax.vmap(cross_pair, in_axes=(0, 0, 0, 0, 0, None, None))\n",
    "        offspring_keys = jax.random.split(cross_key, self.n_pop_size)\n",
    "        offspring_geno, offspring_ibd = vmapped_cross(\n",
    "            offspring_keys, mothers_geno, fathers_geno, mothers_ibd, fathers_ibd, self.genetic_map, self.max_crossovers\n",
    "        )\n",
    "        \n",
    "        new_generation = state.generation + 1\n",
    "        new_ids = jnp.arange(self.n_pop_size, dtype=jnp.int32) + state.next_id\n",
    "        new_meta = jnp.stack([\n",
    "            new_ids,\n",
    "            sorted_parent_pool.meta[mother_indices, 0],\n",
    "            sorted_parent_pool.meta[father_indices, 0],\n",
    "            jnp.full((self.n_pop_size,), new_generation, dtype=jnp.int32),\n",
    "        ], axis=-1)\n",
    "        \n",
    "        new_population = Population(geno=offspring_geno, ibd=offspring_ibd, meta=new_meta)\n",
    "        \n",
    "        next_state = BreedingState(\n",
    "            population=new_population, key=key, generation=new_generation, next_id=state.next_id + self.n_pop_size\n",
    "        )\n",
    "        \n",
    "        done = next_state.generation >= self.total_gen\n",
    "\n",
    "        def get_final_reward(final_state: BreedingState):\n",
    "            reward_key, _ = jax.random.split(final_state.key)\n",
    "            _, tbvs = calculate_phenotypes(\n",
    "                reward_key, final_state.population, self.trait_architecture, self.heritabilities\n",
    "            )\n",
    "            return jnp.mean(tbvs[:, 0])\n",
    "\n",
    "        reward = jax.lax.cond(done, get_final_reward, lambda s: 0.0, operand=next_state)\n",
    "        \n",
    "        obs = self._get_obs(next_state)\n",
    "        return obs, next_state, reward, done, {}\n",
    "\n",
    "    def reset_env(self, key: jax.Array, params) -> Tuple[jax.Array, BreedingState]:\n",
    "        \"\"\"\n",
    "        Resets the environment. Includes a \"burn-in\" step to ensure the\n",
    "        initial population size matches the ongoing population size, which is\n",
    "        required for JAX's conditional logic in auto-resetting environments.\n",
    "        \"\"\"\n",
    "        # Create a new state with the small founder population at generation 0\n",
    "        burn_in_key, pheno_key, mating_key, cross_key = jax.random.split(key, 4)\n",
    "        founder_state = BreedingState(\n",
    "            population=self.founder_pop, key=burn_in_key, generation=0, next_id=self.n_founders\n",
    "        )\n",
    "        \n",
    "        # --- Perform a single burn-in breeding step to reach `n_pop_size` ---\n",
    "        phenotypes, _ = calculate_phenotypes(\n",
    "            pheno_key, founder_state.population, self.trait_architecture, self.heritabilities\n",
    "        )\n",
    "        \n",
    "        # Select top 50% of founders by default for the first cross\n",
    "        n_select = jnp.maximum(2, self.n_founders // 2)\n",
    "        sorted_indices = jnp.argsort(-phenotypes[:, 0].flatten())\n",
    "        sorted_founders = tree_map(lambda x: x[sorted_indices], founder_state.population)\n",
    "        \n",
    "        pairings = random_mating(mating_key, n_parents=n_select, n_crosses=self.n_pop_size)\n",
    "        mother_indices, father_indices = pairings[:, 0], pairings[:, 1]\n",
    "        \n",
    "        mothers_geno = sorted_founders.geno[mother_indices]\n",
    "        fathers_geno = sorted_founders.geno[father_indices]\n",
    "        mothers_ibd = sorted_founders.ibd[mother_indices]\n",
    "        fathers_ibd = sorted_founders.ibd[father_indices]\n",
    "\n",
    "        vmapped_cross = jax.vmap(cross_pair, in_axes=(0, 0, 0, 0, 0, None, None))\n",
    "        offspring_keys = jax.random.split(cross_key, self.n_pop_size)\n",
    "        offspring_geno, offspring_ibd = vmapped_cross(\n",
    "            offspring_keys, mothers_geno, fathers_geno, mothers_ibd, fathers_ibd, self.genetic_map, self.max_crossovers\n",
    "        )\n",
    "        \n",
    "        # This is the actual initial state for the agent at generation 1\n",
    "        initial_gen = 1\n",
    "        initial_ids = jnp.arange(self.n_pop_size, dtype=jnp.int32) + founder_state.next_id\n",
    "        initial_meta = jnp.stack([\n",
    "            initial_ids,\n",
    "            sorted_founders.meta[mother_indices, 0],\n",
    "            sorted_founders.meta[father_indices, 0],\n",
    "            jnp.full((self.n_pop_size,), initial_gen, dtype=jnp.int32),\n",
    "        ], axis=-1)\n",
    "        \n",
    "        initial_pop = Population(geno=offspring_geno, ibd=offspring_ibd, meta=initial_meta)\n",
    "        \n",
    "        # The state returned to the agent\n",
    "        initial_state = BreedingState(\n",
    "            population=initial_pop, key=key, generation=initial_gen, next_id=founder_state.next_id + self.n_pop_size\n",
    "        )\n",
    "\n",
    "        obs = self._get_obs(initial_state)\n",
    "        return obs, initial_state\n",
    "\n",
    "    def _get_obs(self, state: BreedingState) -> jax.Array:\n",
    "        remaining_gen = jnp.maximum(0.0, (self.total_gen - state.generation) / self.total_gen)\n",
    "        pheno_key, _ = jax.random.split(state.key)\n",
    "        phenotypes, _ = calculate_phenotypes(\n",
    "            key=pheno_key, population=state.population, trait=self.trait_architecture, heritability=self.heritabilities\n",
    "        )\n",
    "        pheno_trait_1 = phenotypes[:, 0]\n",
    "        genetic_mean = jnp.mean(pheno_trait_1)\n",
    "        genetic_var = jnp.var(pheno_trait_1)\n",
    "        return jnp.array([remaining_gen, genetic_mean, genetic_var])\n",
    "\n",
    "    def observation_space(self, params):\n",
    "        low = jnp.array([0.0, -jnp.inf, 0.0], dtype=jnp.float32)\n",
    "        high = jnp.array([1.0, jnp.inf, jnp.inf], dtype=jnp.float32)\n",
    "        return spaces.Box(low, high, (3,), dtype=jnp.float32)\n",
    "\n",
    "    def action_space(self, params):\n",
    "        return spaces.Box(low=-1.0, high=1.0, shape=(1,), dtype=jnp.float32)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # --- Example Usage ---\n",
    "    env = StoaEnv(total_gen=5)\n",
    "    key = jax.random.PRNGKey(0)\n",
    "    env_params = env.default_params\n",
    "    \n",
    "    print(\"--- Resetting Environment ---\")\n",
    "    reset_key, step_key = jax.random.split(key)\n",
    "    obs, state = env.reset(reset_key)\n",
    "    \n",
    "    print(f\"Initial Observation (Gen {state.generation}): {obs}\")\n",
    "    print(f\"Initial Population Size: {state.population.geno.shape[0]}\")\n",
    "\n",
    "    # --- Jitting the step function ---\n",
    "    step_fn = jax.jit(env.step)\n",
    "    \n",
    "    # --- Run a full episode and store history ---\n",
    "    print(\"\\n--- Running a Full Episode ---\")\n",
    "    \n",
    "    # Store the history of observations and rewards\n",
    "    history = []\n",
    "    cumulative_reward = 0.0\n",
    "    \n",
    "    # Episode length is total_gen minus the starting generation (1)\n",
    "    for _ in range(env.total_gen - state.generation):\n",
    "        step_key, action_key = jax.random.split(step_key)\n",
    "        action = env.action_space(env_params).sample(action_key)\n",
    "        \n",
    "        # Store the state *before* the step to log it with the resulting reward\n",
    "        current_state = state\n",
    "        \n",
    "        obs, state, reward, done, _ = step_fn(step_key, current_state, action, env_params)\n",
    "        cumulative_reward += reward\n",
    "\n",
    "        history.append({\n",
    "            \"generation\": current_state.generation + 1,\n",
    "            \"mean_pheno\": obs[1],\n",
    "            \"reward\": reward,\n",
    "            \"done\": done\n",
    "        })\n",
    "\n",
    "    # --- Print the results sequentially ---\n",
    "    for step_info in history:\n",
    "        print(\n",
    "            f\"Gen {step_info['generation']}: \"\n",
    "            f\"Mean Pheno={step_info['mean_pheno']:.2f}, \"\n",
    "            f\"Reward={step_info['reward']:.2f}, \"\n",
    "            f\"Done={step_info['done']}\"\n",
    "        )\n",
    "    \n",
    "    print(f\"\\nFinal Cumulative Reward (equal to final TBV): {cumulative_reward:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008a15ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
